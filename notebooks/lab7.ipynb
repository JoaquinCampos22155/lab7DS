{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ea325f",
   "metadata": {},
   "source": [
    "# Lab 7 DATA SCIENCE Guia Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1dec3-2b54-4854-af6c-0fc5c6622109",
   "metadata": {},
   "source": [
    "## Creacion de la aplicacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63d033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/26 04:34:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pyspark.sql.session.SparkSession at 0x7f38d3251090>,\n",
       " 'local[*]',\n",
       " '/opt/app/working_dir/')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# ruta DENTRO DEL CONTENEDOR\n",
    "working_dir = \"/opt/app/working_dir/\"\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Lab7-RDDs\")\n",
    "         .master(\"local[*]\")\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark, sc.master, working_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c5350",
   "metadata": {},
   "source": [
    "## Exploracion basica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ad08b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo (3 líneas): ['We the People of the United States, in Order to form a more perfect ', 'Union, establish Justice, insure domestic Tranquility, provide for the ', 'common defence, promote the general Welfare, and secure the Blessings of ']\n",
      "Número de líneas: 649\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.textFile(working_dir + \"constitution.txt\")\n",
    "print(\"Ejemplo (3 líneas):\", rdd.take(3))\n",
    "print(\"Número de líneas:\", rdd.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfc92ee-8eb8-4912-8588-d51f5011d82c",
   "metadata": {},
   "source": [
    "Usando el count podemos definir la cantidad de líneas en este caso tenemos 649 líneas sin definir el split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da43d7-525b-4d9b-8bb5-db1ac494769b",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f82165fd-efa1-4802-9b8e-f9dadf6e992a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo (3 elementos): [['We', 'the', 'People', 'of', 'the', 'United', 'States,', 'in', 'Order', 'to', 'form', 'a', 'more', 'perfect', ''], ['Union,', 'establish', 'Justice,', 'insure', 'domestic', 'Tranquility,', 'provide', 'for', 'the', ''], ['common', 'defence,', 'promote', 'the', 'general', 'Welfare,', 'and', 'secure', 'the', 'Blessings', 'of', '']]\n",
      "Tipo del primer elemento: <class 'list'>\n",
      "¿Cuántos elementos tiene splitted_lines?: 649\n"
     ]
    }
   ],
   "source": [
    "splitted_lines = rdd.map(lambda line: line.split(' '))\n",
    "\n",
    "print(\"Ejemplo (3 elementos):\", splitted_lines.take(3))\n",
    "print(\"Tipo del primer elemento:\", type(splitted_lines.take(1)[0]))\n",
    "print(\"¿Cuántos elementos tiene splitted_lines?:\", splitted_lines.count())  # ¿qué te da?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f7ff9-2704-4639-b5e9-175d03f415df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "No cumple aún con el propósito porque incluso sigue contando las líneas y en el output podemos ver que esta agrupando incorrectamente el split. un RDD donde cada elemento es una lista de palabras, no una palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71c8311b-0885-4696-9ade-7e25b124d846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra de palabras: ['We', 'the', 'People', 'of', 'the', 'United', 'States,', 'in', 'Order', 'to']\n",
      "Total de 'palabras': 8435\n"
     ]
    }
   ],
   "source": [
    "words_rdd = rdd.flatMap(lambda line: line.split(' '))\n",
    "\n",
    "print(\"Muestra de palabras:\", words_rdd.take(10))\n",
    "print(\"Total de 'palabras':\", words_rdd.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cb5cf3-803a-4d00-82eb-88a14d7c05b0",
   "metadata": {},
   "source": [
    "Con flatMap cada elemento del RDD pasó a ser una palabra individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928d9cfc-e2bd-468b-893a-ef085668aa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens tras filtrar vacíos: 7623\n"
     ]
    }
   ],
   "source": [
    "words_rdd_clean_split_space = (rdd\n",
    "    .flatMap(lambda line: line.split(' '))\n",
    "    .filter(lambda w: w != \"\"))\n",
    "\n",
    "print(\"Tokens tras filtrar vacíos:\", words_rdd_clean_split_space.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdcbd2-8a75-4bc3-8c9f-42e45b213b2a",
   "metadata": {},
   "source": [
    "Se convirtió cada línea en palabras usando flatMap y separando por espacio, entonces el valor impreso corresponde al total de tokens reales del documento sin vaciios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5568177a-d729-47b4-bd3c-9df3ef3dfc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Representatives,', 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_raw = words_rdd_clean_split_space.reduce(\n",
    "    lambda a, b: a if len(a) > len(b) else b\n",
    ")\n",
    "longest_raw, len(longest_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d623d-6df7-4c51-8279-2c4de7d427cb",
   "metadata": {},
   "source": [
    "comparando longitudes el resultado todavía puede incluir signos de puntuación pero se considera la mas larga por el momento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa39706-7026-421f-a46e-794f9b52c9e6",
   "metadata": {},
   "source": [
    "### Configuracion con isalnum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c285311-966e-4a4b-b154-a99bb31ca726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('constitutionally', 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_clean = (words_rdd_clean_split_space\n",
    "               .filter(lambda w: w.isalnum())\n",
    "               .map(lambda w: w.lower()))\n",
    "\n",
    "longest_clean = words_clean.reduce(\n",
    "    lambda a, b: a if len(a) > len(b) else b\n",
    ")\n",
    "longest_clean, len(longest_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a46f3-6e39-4d50-b319-1e46f0543ff9",
   "metadata": {},
   "source": [
    "Ahora sí sin usar la coma en representatives ni considerarlas siendo \"minusculas\" convertidas pero sin ningun caracter especial podemos si encontrar la palabra mas larga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4908f1-6b13-4d69-bb5f-e15a2ce0b02d",
   "metadata": {},
   "source": [
    "## KEY-VALUE RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eb5a6d3-b27d-4283-a5e5-54dfc65e12ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordcount: [('We', 2), ('of', 493), ('United', 85), ('States,', 55), ('Order', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Convirtiendo a rdd a keyvalues: \n",
    "\n",
    "base_words_rdd = globals().get(\"words_rdd\", None) or words_rdd_clean_split_space\n",
    "\n",
    "keyval_rdd = base_words_rdd.map(lambda w: (w, 1))\n",
    "wordcount = keyval_rdd.reduceByKey(lambda a, b: a + b)\n",
    "print(\"wordcount:\", wordcount.take(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f1273-6eb4-4760-92d0-01fa31520cf8",
   "metadata": {},
   "source": [
    "Esto permite obtener el conteo individual por palabra de forma eficiente en paralelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c12396e-f34b-4f02-b3ed-f574e8005f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(812, ''), (662, 'the'), (493, 'of'), (293, 'shall'), (256, 'and')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_wc = (wordcount\n",
    "             .map(lambda x: (x[1], x[0]))  \n",
    "             .sortByKey(ascending=False))  \n",
    "\n",
    "top5 = sorted_wc.take(5)\n",
    "top5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51d6cc5c-a841-4012-b597-c59ef0ed8dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(726, 'the'), (493, 'of'), (293, 'shall'), (262, 'and'), (201, 'to')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount_clean = (words_clean\n",
    "                   .map(lambda w: (w, 1))\n",
    "                   .reduceByKey(lambda a, b: a + b))\n",
    "\n",
    "top5_clean = (wordcount_clean\n",
    "              .map(lambda x: (x[1], x[0]))\n",
    "              .sortByKey(ascending=False)\n",
    "              .take(5))\n",
    "top5_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b595c236-6543-4f11-9804-22dcbbbb5b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(85, 'united'),\n",
       " (72, 'president'),\n",
       " (47, 'states'),\n",
       " (39, 'congress'),\n",
       " (34, 'amendment')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = {\n",
    "    'the','of','and','to','in','a','that','is','for','on','with','as','by','be','are','was','were',\n",
    "    'this','it','or','an','from','at','which','but','not','have','has','had','shall','state','may','any','no','all','such' \n",
    "}\n",
    "\n",
    "wordcount_nostop = (words_clean\n",
    "                    .filter(lambda w: w not in stopwords)\n",
    "                    .map(lambda w: (w, 1))\n",
    "                    .reduceByKey(lambda a, b: a + b))\n",
    "\n",
    "top5_nostop = (wordcount_nostop\n",
    "               .map(lambda x: (x[1], x[0])) \n",
    "               .sortByKey(ascending=False)\n",
    "               .take(5))\n",
    "top5_nostop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c16baf-7356-4244-9805-5a76fdfa8d52",
   "metadata": {},
   "source": [
    "Por el simple interes de conocer se ha agregado a los stopwords tambien \"no\" ya que no necesariamente es un stopword en el sentido que no es conector directamente, y state porque ya esta states en plural dentro de los \"ganadores\". \n",
    "\n",
    "---\n",
    "\n",
    "En cuanto a comentarios sobre spark puede ser un poco mas abstracto no necesariamente mas como, cómo? tenemos que hacer exactamente algo sino que y ya. Interesante porque ayuda a trabajar con archivos grandes.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
